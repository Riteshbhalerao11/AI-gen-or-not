{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":61542,"databundleVersionId":6888007,"sourceType":"competition"},{"sourceId":6977472,"sourceType":"datasetVersion","datasetId":4005256},{"sourceId":2233309,"sourceType":"datasetVersion","datasetId":1335671}],"dockerImageVersionId":30635,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport regex as re\nfrom sklearn.metrics.pairwise import linear_kernel\nimport matplotlib.pyplot as plt\nfrom scipy.sparse import  vstack\nimport random\nfrom transformers import BertTokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport tensorflow_addons as tfa\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Attention, Input, Dense, concatenate, MaxPooling1D, Activation, Add, Flatten, Conv1D, Conv2D\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nimport tensorflow_text as tf_text\n\nfrom tensorflow.keras.layers import TextVectorization, Embedding, Bidirectional, LSTM, Conv1D, GlobalMaxPooling1D, Dense, Reshape , GlobalAveragePooling2D\nfrom tensorflow.keras import Model, Input","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-13T13:00:43.948901Z","iopub.execute_input":"2024-01-13T13:00:43.949287Z","iopub.status.idle":"2024-01-13T13:00:50.442643Z","shell.execute_reply.started":"2024-01-13T13:00:43.949256Z","shell.execute_reply":"2024-01-13T13:00:50.441771Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n\nTensorFlow Addons (TFA) has ended development and introduction of new features.\nTFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\nPlease modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n\nFor more information see: https://github.com/tensorflow/addons/issues/2807 \n\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"sub = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/sample_submission.csv')\ndf_test = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv')\ntrain_extra = pd.read_csv(\"/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv\", sep=',')","metadata":{"execution":{"iopub.status.busy":"2024-01-13T13:00:50.444286Z","iopub.execute_input":"2024-01-13T13:00:50.444905Z","iopub.status.idle":"2024-01-13T13:00:51.522354Z","shell.execute_reply.started":"2024-01-13T13:00:50.444876Z","shell.execute_reply":"2024-01-13T13:00:51.521467Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"tok_path = '/kaggle/input/huggingface-bert-variants/bert-base-cased/bert-base-cased'","metadata":{"execution":{"iopub.status.busy":"2024-01-13T13:00:51.523461Z","iopub.execute_input":"2024-01-13T13:00:51.523734Z","iopub.status.idle":"2024-01-13T13:00:51.528138Z","shell.execute_reply.started":"2024-01-13T13:00:51.523712Z","shell.execute_reply":"2024-01-13T13:00:51.527103Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_extra = train_extra[train_extra['source'] != 'train_essays']\ntrain_extra = train_extra[train_extra.RDizzl3_seven]\ntrain_extra.drop(columns=['source','RDizzl3_seven'],inplace=True)\ntrain_extra.rename(columns={'label' : 'generated'}, inplace=True)\ndf_train = train_extra\ndf_train.reset_index(inplace=True,drop=True)\nset(train_extra.prompt_name.tolist())","metadata":{"execution":{"iopub.status.busy":"2024-01-13T13:00:51.530353Z","iopub.execute_input":"2024-01-13T13:00:51.530656Z","iopub.status.idle":"2024-01-13T13:00:51.563351Z","shell.execute_reply.started":"2024-01-13T13:00:51.530630Z","shell.execute_reply":"2024-01-13T13:00:51.562371Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"{'\"A Cowboy Who Rode the Waves\"',\n 'Car-free cities',\n 'Does the electoral college work?',\n 'Driverless cars',\n 'Exploring Venus',\n 'Facial action coding system',\n 'The Face on Mars'}"},"metadata":{}}]},{"cell_type":"code","source":"label_encoder = LabelEncoder()\ndf_train['prompt_name'] = label_encoder.fit_transform(df_train['prompt_name'])","metadata":{"execution":{"iopub.status.busy":"2024-01-13T13:00:51.564879Z","iopub.execute_input":"2024-01-13T13:00:51.565277Z","iopub.status.idle":"2024-01-13T13:00:51.576071Z","shell.execute_reply.started":"2024-01-13T13:00:51.565241Z","shell.execute_reply":"2024-01-13T13:00:51.575153Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{"execution":{"iopub.status.busy":"2024-01-13T13:00:51.577492Z","iopub.execute_input":"2024-01-13T13:00:51.577808Z","iopub.status.idle":"2024-01-13T13:00:51.595545Z","shell.execute_reply.started":"2024-01-13T13:00:51.577783Z","shell.execute_reply":"2024-01-13T13:00:51.594547Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                    text  generated  \\\n0      Cars have been around for awhile and they have...          0   \n1      Have you ever thought what it would be like no...          0   \n2      What you are about to read is going to give yo...          0   \n3      cars have many flaws nd and in this day and ag...          0   \n4      There are many advantages of limiting car usag...          0   \n...                                                  ...        ...   \n19067  Dear Senator,\\n\\nI am writing to you today to ...          1   \n19068  Dear Senator,\\n\\nI am writing to you today to ...          1   \n19069  Dear Senator,\\n\\nI am writing to you today to ...          1   \n19070  Dear Senator,\\n\\nI am writing to you today to ...          1   \n19071  Dear Senator,\\n\\nI am writing to you today to ...          1   \n\n       prompt_name  \n0                1  \n1                1  \n2                1  \n3                1  \n4                1  \n...            ...  \n19067            2  \n19068            2  \n19069            2  \n19070            2  \n19071            2  \n\n[19072 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>generated</th>\n      <th>prompt_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cars have been around for awhile and they have...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Have you ever thought what it would be like no...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>What you are about to read is going to give yo...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cars have many flaws nd and in this day and ag...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>There are many advantages of limiting car usag...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19067</th>\n      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>19068</th>\n      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>19069</th>\n      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>19070</th>\n      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>19071</th>\n      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>19072 rows Ã— 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\nprint(\"\\nLabel Mapping:\")\nprint(label_mapping)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T13:00:51.596760Z","iopub.execute_input":"2024-01-13T13:00:51.597065Z","iopub.status.idle":"2024-01-13T13:00:51.603098Z","shell.execute_reply.started":"2024-01-13T13:00:51.597040Z","shell.execute_reply":"2024-01-13T13:00:51.602028Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"\nLabel Mapping:\n{'\"A Cowboy Who Rode the Waves\"': 0, 'Car-free cities': 1, 'Does the electoral college work?': 2, 'Driverless cars': 3, 'Exploring Venus': 4, 'Facial action coding system': 5, 'The Face on Mars': 6}\n","output_type":"stream"}]},{"cell_type":"code","source":"train_size = df_train.shape[0]","metadata":{"execution":{"iopub.status.busy":"2024-01-13T13:00:51.604490Z","iopub.execute_input":"2024-01-13T13:00:51.604939Z","iopub.status.idle":"2024-01-13T13:00:51.615257Z","shell.execute_reply.started":"2024-01-13T13:00:51.604909Z","shell.execute_reply":"2024-01-13T13:00:51.614287Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def clean_text(text):\n    # Replace actual newline and carriage return characters with whitespace\n    text = text.replace(\"\\n\", \" \")\n    text = text.replace(\"\\r\", \" \")\n    \n    # Drop punctuation\n    text = re.sub(r\"\\p{P}\", \" \", text)\n    \n    # Remove extra spaces\n    text = re.sub(r\"\\s+\", \" \", text)\n    \n    # Remove leading and trailing whitespace\n    text = text.strip()\n    \n    # Lower text\n    text = text.lower()\n    \n    # Remove numbers\n    text = re.sub(r\"\\d+\", \"\", text)\n    \n    return text\n\ndf_train['text'] =  df_train['text'].apply(clean_text)\ndf_test['text'] = df_test['text'].apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T13:00:51.616612Z","iopub.execute_input":"2024-01-13T13:00:51.617373Z","iopub.status.idle":"2024-01-13T13:00:58.038882Z","shell.execute_reply.started":"2024-01-13T13:00:51.617338Z","shell.execute_reply":"2024-01-13T13:00:58.037835Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Change contractions\ncontractions = {\n    r'\\b(can\\'t)\\b': 'cannot',\n    r'\\b(don\\'t)\\b': 'do not',\n    r'\\b(won\\'t)\\b': 'will not',\n}\n\n# Iterate through contractions and apply replacements to the entire DataFrame column\nfor pattern, replacement in contractions.items():\n    df_train['text'] =  df_train['text'].apply(lambda x: re.sub(pattern, replacement, x, flags=re.IGNORECASE))\n    df_test['text'] =  df_test['text'].apply(lambda x: re.sub(pattern, replacement, x, flags=re.IGNORECASE))","metadata":{"execution":{"iopub.status.busy":"2024-01-13T13:00:58.042486Z","iopub.execute_input":"2024-01-13T13:00:58.042829Z","iopub.status.idle":"2024-01-13T13:00:58.854184Z","shell.execute_reply.started":"2024-01-13T13:00:58.042792Z","shell.execute_reply":"2024-01-13T13:00:58.853343Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"text_data = pd.concat([df_train.text,df_test.text])\ntext_data","metadata":{"execution":{"iopub.status.busy":"2024-01-13T13:00:58.855207Z","iopub.execute_input":"2024-01-13T13:00:58.855464Z","iopub.status.idle":"2024-01-13T13:00:58.864363Z","shell.execute_reply.started":"2024-01-13T13:00:58.855441Z","shell.execute_reply":"2024-01-13T13:00:58.863461Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"0        cars have been around for awhile and they have...\n1        have you ever thought what it would be like no...\n2        what you are about to read is going to give yo...\n3        cars have many flaws nd and in this day and ag...\n4        there are many advantages of limiting car usag...\n                               ...                        \n19070    dear senator i am writing to you today to expr...\n19071    dear senator i am writing to you today to expr...\n0                                              aaa bbb ccc\n1                                              bbb ccc ddd\n2                                              ccc ddd eee\nName: text, Length: 19075, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"vectorizer = TfidfVectorizer(ngram_range=(3, 5), sublinear_tf=True)\ntf_idf = vectorizer.fit_transform(text_data.values)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T13:00:58.865632Z","iopub.execute_input":"2024-01-13T13:00:58.865926Z","iopub.status.idle":"2024-01-13T13:02:40.356657Z","shell.execute_reply.started":"2024-01-13T13:00:58.865902Z","shell.execute_reply":"2024-01-13T13:02:40.355773Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"tf_idf_train = tf_idf[:train_size]\ntf_idf_test = tf_idf[train_size:]","metadata":{"execution":{"iopub.status.busy":"2024-01-13T13:02:40.357920Z","iopub.execute_input":"2024-01-13T13:02:40.358222Z","iopub.status.idle":"2024-01-13T13:02:40.726884Z","shell.execute_reply.started":"2024-01-13T13:02:40.358197Z","shell.execute_reply":"2024-01-13T13:02:40.725856Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"del tf_idf","metadata":{"execution":{"iopub.status.busy":"2024-01-13T13:02:40.728199Z","iopub.execute_input":"2024-01-13T13:02:40.728483Z","iopub.status.idle":"2024-01-13T13:02:40.734157Z","shell.execute_reply.started":"2024-01-13T13:02:40.728460Z","shell.execute_reply":"2024-01-13T13:02:40.733097Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def get_sorted_inds(x):\n    \n    inds = np.zeros((x.shape[0],2),dtype=int)\n    for i in range(x.shape[0]):\n        temp = x[i]\n        if(temp[temp.argmax()] > 0.99):\n            inds[i] = temp.argsort()[-3:-1]\n        else : \n            inds[i] = temp.argsort()[-2:]\n    return inds","metadata":{"execution":{"iopub.status.busy":"2024-01-13T13:02:40.735556Z","iopub.execute_input":"2024-01-13T13:02:40.735921Z","iopub.status.idle":"2024-01-13T13:02:40.744506Z","shell.execute_reply.started":"2024-01-13T13:02:40.735888Z","shell.execute_reply":"2024-01-13T13:02:40.743660Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def get_train_indices(matrix,df):\n    df_indices = df.index\n    tf_idf_matrix = vstack([row for idx, row in enumerate(matrix) if idx in df_indices])\n    \n    temp = df[df['generated'] == 1]\n    flag_1 = temp.empty\n    if(not flag_1):\n        index_list = temp.index\n        mask = [i in index_list for i in df_indices]\n        tf_idf_1 = [row for idx, row in enumerate(tf_idf_matrix) if mask[idx]]\n        tf_idf_1 = vstack(tf_idf_1)\n    \n    temp = df[df['generated'] == 0]\n    flag_2 = temp.empty\n    if(not flag_2):\n        index_list = temp.index\n        mask = [i in index_list for i in df_indices]\n        tf_idf_0 = [row for idx, row in enumerate(tf_idf_matrix) if mask[idx]]\n        tf_idf_0 = vstack(tf_idf_0)\n    \n    cs_1 = linear_kernel(tf_idf_matrix, tf_idf_1)\n    cs_0 = linear_kernel(tf_idf_matrix, tf_idf_0)\n    \n    inds_1 = get_sorted_inds(cs_1)\n    inds_0 = get_sorted_inds(cs_0)\n    \n    return inds_1,inds_0","metadata":{"execution":{"iopub.status.busy":"2024-01-13T13:02:40.745614Z","iopub.execute_input":"2024-01-13T13:02:40.745975Z","iopub.status.idle":"2024-01-13T13:02:40.755641Z","shell.execute_reply.started":"2024-01-13T13:02:40.745949Z","shell.execute_reply":"2024-01-13T13:02:40.754691Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def make_dataset(df,i1,i0):\n    texts = df.text.values\n    t1 = df[df['generated']==1].text.values\n    t0 = df[df['generated']==0].text.values\n    df_labels = df.generated.values\n    labels = []\n    text_1 = []\n    text_2 = []\n    for i in range(df.shape[0]):\n        text_1.extend([texts[i],texts[i]])\n#         print(t1[i1[i][0]])\n        text_2.extend([t1[i1[i][0]],t1[i1[i][1]]])\n        if(df_labels[i] == 1):\n            labels.extend([1, 1])\n        else:\n            labels.extend([0, 0])\n            \n        text_1.extend([texts[i],texts[i]])\n        text_2.extend([t0[i0[i][0]],t0[i0[i][1]]])\n        if(df_labels[i] == 1):\n            labels.extend([0, 0])\n        else:\n            labels.extend([1, 1])\n    \n    return text_1,text_2,labels","metadata":{"execution":{"iopub.status.busy":"2024-01-13T13:02:40.756716Z","iopub.execute_input":"2024-01-13T13:02:40.757013Z","iopub.status.idle":"2024-01-13T13:02:40.768547Z","shell.execute_reply.started":"2024-01-13T13:02:40.756989Z","shell.execute_reply":"2024-01-13T13:02:40.767687Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"sim_data = pd.DataFrame({'text_1' : [] , 'text_2' : [] , 'similar' : []})","metadata":{"execution":{"iopub.status.busy":"2024-01-13T13:02:40.769599Z","iopub.execute_input":"2024-01-13T13:02:40.769901Z","iopub.status.idle":"2024-01-13T13:02:40.777303Z","shell.execute_reply.started":"2024-01-13T13:02:40.769864Z","shell.execute_reply":"2024-01-13T13:02:40.776516Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"for i in range(7):\n    print(i)\n    i1,i0 = get_train_indices(tf_idf_train,df_train[df_train['prompt_name']==i])\n    x,y,z = make_dataset(df_train[df_train['prompt_name']==i],i1,i0)\n    temp = pd.DataFrame({'text_1' : x , 'text_2' : y , 'similar' : z})\n    sim_data = pd.concat([sim_data,temp])","metadata":{"execution":{"iopub.status.busy":"2024-01-13T13:02:40.778548Z","iopub.execute_input":"2024-01-13T13:02:40.779237Z","iopub.status.idle":"2024-01-13T13:03:03.439754Z","shell.execute_reply.started":"2024-01-13T13:02:40.779202Z","shell.execute_reply":"2024-01-13T13:03:03.438967Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"0\n1\n2\n3\n4\n5\n6\n","output_type":"stream"}]},{"cell_type":"code","source":"sim_data","metadata":{"execution":{"iopub.status.busy":"2024-01-13T13:03:03.440870Z","iopub.execute_input":"2024-01-13T13:03:03.441158Z","iopub.status.idle":"2024-01-13T13:03:03.455427Z","shell.execute_reply.started":"2024-01-13T13:03:03.441133Z","shell.execute_reply":"2024-01-13T13:03:03.454425Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"                                                 text_1  \\\n0     luke the seagoing cowboy i would love to do th...   \n1     luke the seagoing cowboy i would love to do th...   \n2     luke the seagoing cowboy i would love to do th...   \n3     luke the seagoing cowboy i would love to do th...   \n4     people should join the seagoing cowboys progra...   \n...                                                 ...   \n7567  i remember the first time i saw the face on ma...   \n7568  i remember the first time i saw the face on ma...   \n7569  i remember the first time i saw the face on ma...   \n7570  i remember the first time i saw the face on ma...   \n7571  i remember the first time i saw the face on ma...   \n\n                                                 text_2  similar  \n0     introduction have you ever wanted to go on an ...      0.0  \n1     dear friends have you ever wanted to go on an ...      0.0  \n2     is a seagoing cowboy a real thing people might...      1.0  \n3     this persuasive essay is about why you should ...      1.0  \n4     i m glad you asked me to write an essay from t...      0.0  \n...                                                 ...      ...  \n7567  some people think that the face on mars was cr...      0.0  \n7568  i remember the first time i saw the face on ma...      1.0  \n7569  hey listen up i m here to convince you that th...      1.0  \n7570  this article is mostly about nasa and it s dis...      0.0  \n7571  my name is proffesor yado and my colleague and...      0.0  \n\n[76288 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_1</th>\n      <th>text_2</th>\n      <th>similar</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>luke the seagoing cowboy i would love to do th...</td>\n      <td>introduction have you ever wanted to go on an ...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>luke the seagoing cowboy i would love to do th...</td>\n      <td>dear friends have you ever wanted to go on an ...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>luke the seagoing cowboy i would love to do th...</td>\n      <td>is a seagoing cowboy a real thing people might...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>luke the seagoing cowboy i would love to do th...</td>\n      <td>this persuasive essay is about why you should ...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>people should join the seagoing cowboys progra...</td>\n      <td>i m glad you asked me to write an essay from t...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7567</th>\n      <td>i remember the first time i saw the face on ma...</td>\n      <td>some people think that the face on mars was cr...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7568</th>\n      <td>i remember the first time i saw the face on ma...</td>\n      <td>i remember the first time i saw the face on ma...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>7569</th>\n      <td>i remember the first time i saw the face on ma...</td>\n      <td>hey listen up i m here to convince you that th...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>7570</th>\n      <td>i remember the first time i saw the face on ma...</td>\n      <td>this article is mostly about nasa and it s dis...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7571</th>\n      <td>i remember the first time i saw the face on ma...</td>\n      <td>my name is proffesor yado and my colleague and...</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>76288 rows Ã— 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(tok_path, do_lower_case = True)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T13:03:03.456769Z","iopub.execute_input":"2024-01-13T13:03:03.457164Z","iopub.status.idle":"2024-01-13T13:03:03.563069Z","shell.execute_reply.started":"2024-01-13T13:03:03.457136Z","shell.execute_reply":"2024-01-13T13:03:03.562246Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"tokenized_texts = [tokenizer.tokenize(sent) for sent in text_data]","metadata":{"execution":{"iopub.status.busy":"2024-01-13T13:03:03.564358Z","iopub.execute_input":"2024-01-13T13:03:03.564740Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\ninput_ids = pad_sequences(input_ids, maxlen=512, dtype=\"long\", truncating=\"post\", padding=\"post\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_input_ids = input_ids[:train_size]\ntest_input_ids = input_ids[train_size:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_input_ids.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t1 = df_train.text.values\nt1_ids = np.zeros((sim_data.shape[0],512),dtype=int)\ni = 0\nfor ids in train_input_ids:\n    for j in range(4):\n        t1_ids[i+j] = ids\n    i += 4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t1_ids.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t2_inds = []\nt2_ids = np.zeros((sim_data.shape[0],512),dtype=int)\nt2_texts = sim_data.text_2.values\nfor i in range(sim_data.shape[0]):\n    idx = df_train[df_train['text'] == t2_texts[i]].index[0]\n    t2_inds.append(idx*4)\n    \n    if(i % 1000 == 0):\n        print(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_array = np.zeros((2,sim_data.shape[0],512))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_array[0] = t1_ids\ntrain_array[1] = t2_ids","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_array.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del text_data , vectorizer , input_ids, t1_ids , t2_ids, t2_inds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_similar_data(tfidf,tfidf_test):\n    \n    cosine_similarities = linear_kernel(tfidf_test, tfidf)\n    related_docs_indices = cosine_similarities.argsort()[:,-4:]\n\n    \n    return related_docs_indices","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_test_indices(df,tfidf_train,tfidf_test):   \n    \n    temp = df[df['generated'] == 1]\n    flag_1 = temp.empty\n    if(not flag_1):\n        index_list = temp.index\n        mask = [i in index_list for i in df.index]\n        tf_idf_1 = [row for idx, row in enumerate(tfidf_train) if mask[idx]]\n        tf_idf_1 = vstack(tf_idf_1)\n    \n    temp = df[df['generated'] == 0]\n    flag_2 = temp.empty\n    if(not flag_2):\n        index_list = temp.index\n        mask = [i in index_list for i in df.index]\n        tf_idf_0 = [row for idx, row in enumerate(tfidf_train) if mask[idx]]\n        tf_idf_0 = vstack(tf_idf_0)\n    \n    cs_1 = linear_kernel(tfidf_test, tf_idf_1)\n    cs_0 = linear_kernel(tfidf_test, tf_idf_0)\n    \n    return cs_1, cs_0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ids1,ids0 = get_test_indices(df_train,tf_idf_train,tf_idf_test) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_array = np.zeros((2,df_test.shape[0]*8,512))\ndef make_test_data(df,ids1,ids0):\n    \n    df_1 = df[df['generated'] == 1].index.tolist()\n    df_0 = df[df['generated'] == 0].index.tolist()\n    \n    in_1 = train_input_ids[df_1]\n    in_0 = train_input_ids[df_0]\n    \n    ids1 = ids1.argsort()[:,-4:]\n    ids0 = ids0.argsort()[:,-4:]\n    \n    for i in range(df_test.shape[0]):\n        temp = ids1[i]\n        for j in range(4):\n            test_array[0,j] = test_input_ids[i]\n            test_array[1,j] = train_input_ids[temp[j]]\n            \n        temp = ids0[i]\n        for j in range(4,8):\n            test_array[0,j] = test_input_ids[i]\n            test_array[1,j] = train_input_ids[temp[j-4]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_test_data(df_train,ids1,ids0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TransformerBlock(tf.keras.layers.Layer):\n    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n        super(TransformerBlock, self).__init__()\n        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n        self.ffn = tf.keras.Sequential(\n            [tf.keras.layers.Dense(ff_dim, activation=\"relu\"), tf.keras.layers.Dense(embed_dim),]\n        )\n        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n        self.dropout1 = tf.keras.layers.Dropout(rate)\n        self.dropout2 = tf.keras.layers.Dropout(rate)\n\n    def call(self, inputs, training):\n        attn_output = self.att(inputs, inputs)\n        attn_output = self.dropout1(attn_output, training=training)\n        out1 = self.layernorm1(inputs + attn_output)\n        ffn_output = self.ffn(out1)\n        ffn_output = self.dropout2(ffn_output, training=training)\n        return self.layernorm2(out1 + ffn_output)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_features = 75000\nembedding_dim = 64\nsequence_length = 512","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def createModel(embedding,bidirectional,transformer_block,conv_1d,globalmaxpool,inputs):\n    x = embedding(inputs)\n    x = bidirectional(x)\n    x = transformer_block(x)\n    x = conv_1d(x)\n    x = globalmaxpool(x)\n    model = Model(inputs= inputs, outputs=x)\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def concat_model():\n    \n    inputs_0 = Input(shape=(sequence_length,), dtype=\"int64\")\n    inputs_1 = Input(shape=(sequence_length,), dtype=\"int64\")\n    \n    embedding = Embedding(max_features, embedding_dim)\n    bidirectional = Bidirectional(LSTM(32, return_sequences=True))\n    transformer_block = TransformerBlock(embedding_dim, 2, 32)\n    conv_1d = Conv1D(128, 3, padding=\"valid\", activation=\"relu\", strides=3)\n    globalmaxpool = GlobalMaxPooling1D()\n\n    model1 = createModel(embedding,bidirectional,transformer_block,conv_1d,globalmaxpool,inputs_0)\n    model2 = createModel(embedding,bidirectional,transformer_block,conv_1d,globalmaxpool,inputs_1)\n\n    combined = concatenate([model1.output, model2.output])\n    \n    combined_reshaped = Reshape((2,128, 1))(combined)\n    \n    conv2d_2 = Conv2D(128, (2, 3), activation=\"relu\")(combined_reshaped)\n    avg_pool_2 = GlobalAveragePooling2D()(conv2d_2)\n    conv2d_4 = Conv2D(128, (2, 5), activation=\"relu\")(combined_reshaped)\n    avg_pool_4 = GlobalAveragePooling2D()(conv2d_4)\n    conv2d_5 = Conv2D(128, (2, 7), activation=\"relu\")(combined_reshaped)\n    avg_pool_5 = GlobalAveragePooling2D()(conv2d_5)\n    \n    concatenated_avgpools = concatenate([avg_pool_2, avg_pool_4, avg_pool_5])\n\n    dense = Dense(256, activation=\"relu\")(concatenated_avgpools)\n    dense_1 = Dense(128, activation=\"relu\")(dense)\n    dense_2 = Dense(32, activation=\"relu\")(dense)\n\n    output = Dense(1, activation=\"sigmoid\")(dense)\n\n    model = Model(inputs=[inputs_0, inputs_1], outputs=output)\n    model.summary()\n    adam = Adam(learning_rate=1e-5)\n    model.compile(optimizer=adam, loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), metrics=['acc', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = concat_model()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 5\nmodel.fit(x = [train_array[0],train_array[1]],y = sim_data.similar.values,\n          epochs=epochs, shuffle=True,batch_size = 64 )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model.predict(test_array)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = []\nfor i in range(0,preds.shape[0],8):\n    \n    p0 = preds[i:i+4].mean()\n    p1 = preds[i+4 : i+8].mean()\n    \n    if(p0 > p1):\n        predictions.append(p0)\n    \n    else :\n        predictions.append(p1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subs = pd.DataFrame({'id' : test.id, 'generated' : predictions})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subs.to_csv(\"submission.csv\",index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}