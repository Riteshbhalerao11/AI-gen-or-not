{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d38e9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-26 17:02:15.758801: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLNetTokenizer , TFXLNetModel\n",
    "from tqdm import tqdm\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Attention, Input, Dense, LSTM, Embedding, Bidirectional, Dropout, TimeDistributed, concatenate, MaxPooling1D, Activation, Add, Flatten, Conv1D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b07f344",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_big = pd.read_csv(\"Datasets/train_v2_drcat_02.csv\", sep=',')\n",
    "org_train = pd.read_csv('Datasets/train_essays.csv')\n",
    "train_small = pd.read_csv('Datasets/argugpt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13495e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "select = []\n",
    "for text in train_small.text.values:\n",
    "    if(len(text.split()) > 100):\n",
    "        select.append(1)\n",
    "    else:\n",
    "        select.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcbe1b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3896"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed316c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_small_1 = train_small.copy()\n",
    "train_small_1['select'] = select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dc552a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_small_1 = train_small_1[train_small_1['select'] == 1].copy()\n",
    "dataset_small_1['label'] = 1\n",
    "dataset_small_1 = dataset_small_1[['text','label']]\n",
    "\n",
    "del train_small_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd6d2d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "select = []\n",
    "for text in train_big[train_big['label']==1].text.values:\n",
    "    if(len(text.split()) > 100):\n",
    "        select.append(1)\n",
    "    else:\n",
    "        select.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b210ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17417"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2107af59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_big_1 = train_big[train_big['label']==1].copy()\n",
    "train_big_1['select'] = select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3b46f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_big_1 = train_big_1[train_big_1['select'] == 1].sample(n=9100,random_state=42)\n",
    "dataset_big_1 = dataset_big_1[['text','label']]\n",
    "del train_big_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f668cf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = pd.concat([dataset_big_1,dataset_small_1])\n",
    "dataset_1.reset_index(drop=True,inplace=True)\n",
    "del dataset_big_1\n",
    "del dataset_small_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d4fa7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When it comes to having someone attempt to mak...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dear State Senator, \\n\\nI am writing to you ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey, Mrs. Johnson! Here's my essay on the cons...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In recent years, there has been a growing move...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12991</th>\n",
       "      <td>The notion that one must be forced to defend a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12992</th>\n",
       "      <td>I strongly agree with the statement that menta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12993</th>\n",
       "      <td>In today’s world, where competition is highly ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12994</th>\n",
       "      <td>Education is one of the most powerful tools th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12995</th>\n",
       "      <td>As the world is evolving rapidly, the need for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12996 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  generated\n",
       "0      When it comes to having someone attempt to mak...          1\n",
       "1        Dear State Senator, \\n\\nI am writing to you ...          1\n",
       "2      Hey, Mrs. Johnson! Here's my essay on the cons...          1\n",
       "3      In recent years, there has been a growing move...          1\n",
       "4      Dear Senator,\\n\\nI am writing to you today to ...          1\n",
       "...                                                  ...        ...\n",
       "12991  The notion that one must be forced to defend a...          1\n",
       "12992  I strongly agree with the statement that menta...          1\n",
       "12993  In today’s world, where competition is highly ...          1\n",
       "12994  Education is one of the most powerful tools th...          1\n",
       "12995  As the world is evolving rapidly, the need for...          1\n",
       "\n",
       "[12996 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_1.rename(columns={'label':'generated'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cbc4df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "select = []\n",
    "for text in org_train[org_train['generated']==0].text.values:\n",
    "    if(len(text.split()) > 100):\n",
    "        select.append(1)\n",
    "    else:\n",
    "        select.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af11d917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1375"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9504177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_small_0 = org_train[org_train['generated']==0].copy()\n",
    "train_small_0['select'] = select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d92f8d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_small_0 = train_small_0[['text','generated']].copy()\n",
    "del train_small_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a7332ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "select = []\n",
    "for text in train_big[train_big['label']==0].text.values:\n",
    "    if(len(text.split()) > 100):\n",
    "        select.append(1)\n",
    "    else:\n",
    "        select.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9349ffb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27371"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "533e4974",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_big_0 = train_big[train_big['label']==0].copy()\n",
    "train_big_0['select'] = select\n",
    "train_big_0 = train_big_0[train_big_0['select']==1].sample(n=6700,random_state=42)\n",
    "dataset_big_0 = train_big_0[['text','label']].copy()\n",
    "dataset_big_0.rename(columns={'label':'generated'}, inplace=True)\n",
    "del train_big_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01ade4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_0 = pd.concat([dataset_big_0,dataset_small_0])\n",
    "dataset_0.reset_index(drop=True, inplace=True)\n",
    "del dataset_big_0\n",
    "del dataset_small_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4061b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1.rename(columns={'label':'generated'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b1da3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "251402cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls, sep = tokenizer.convert_tokens_to_ids([\"<cls>\", \"<sep>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa1d9566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(dataset,MAX_LEN=256):\n",
    "    \n",
    "    print(\"==========Tokenizing=============\")\n",
    "    sentences = dataset.text.values\n",
    "    labels = dataset.generated.values\n",
    "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "    \n",
    "    print(\"==========Tokens to inputs=============\")\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "    for inputs in input_ids:\n",
    "        inputs[254] = sep\n",
    "        inputs[255] = cls\n",
    "    \n",
    "    # Create attention masks\n",
    "    attention_masks = []\n",
    "\n",
    "    # Create a mask of 1s for each token followed by 0s for padding\n",
    "    for seq in input_ids:\n",
    "        seq_mask = [float(i>0) for i in seq]\n",
    "        attention_masks.append(seq_mask)\n",
    "    \n",
    "    print(\"==========Splitting=============\")\n",
    "        \n",
    "    # Split into training and temporary set\n",
    "    train_inputs, temp_inputs = train_test_split(input_ids,random_state=42, test_size=0.2)\n",
    "\n",
    "    # Split the temporary set into test and dev sets\n",
    "    validation_inputs, test_inputs = train_test_split(temp_inputs,random_state=42, test_size=0.5)\n",
    "\n",
    "    del temp_inputs\n",
    "    \n",
    "    # Split into training and temporary set\n",
    "    train_mask, temp_mask = train_test_split(attention_masks,random_state=42, test_size=0.2)\n",
    "\n",
    "    # Split the temporary set into test and dev sets\n",
    "    validation_mask, test_mask = train_test_split(temp_mask, random_state=42, test_size=0.5)\n",
    "\n",
    "    del temp_mask\n",
    "    \n",
    "    return {'inputs':(train_inputs,validation_inputs,test_inputs), 'masks' : (train_mask, validation_mask, test_mask)}\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3a19882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Tokenizing=============\n",
      "==========Tokens to inputs=============\n",
      "==========Splitting=============\n"
     ]
    }
   ],
   "source": [
    "out = create_data(dataset_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4417dc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs_1,validation_inputs_1,test_inputs_1 = out['inputs']\n",
    "train_mask_1, validation_mask_1, test_mask_1 = out['masks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0a7f259",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_1 , validation_labels_1 , test_labels_1 = (np.ones(shape=(train_inputs_1.shape[0])), \n",
    "                                                        np.ones(shape=(validation_inputs_1.shape[0])),\n",
    "                                                        np.ones(shape=(test_inputs_1.shape[0]))\n",
    "                                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed53db3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Tokenizing=============\n",
      "==========Tokens to inputs=============\n",
      "==========Splitting=============\n"
     ]
    }
   ],
   "source": [
    "out = create_data(dataset_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c9e5e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs_0,validation_inputs_0,test_inputs_0 = out['inputs']\n",
    "train_mask_0, validation_mask_0, test_mask_0 = out['masks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c9d8a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_0 , validation_labels_0 , test_labels_0 = (np.zeros(shape=(train_inputs_0.shape[0])), \n",
    "                                                        np.zeros(shape=(validation_inputs_0.shape[0])),\n",
    "                                                        np.zeros(shape=(test_inputs_0.shape[0]))\n",
    "                                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b00b152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_data(zeros,ones):\n",
    "    zeros = pd.DataFrame(zeros)\n",
    "    ones = pd.DataFrame(ones)\n",
    "    out = pd.concat([ones,zeros])\n",
    "    out.sample(frac=1).reset_index(drop=True)\n",
    "    return np.array(out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01ed4784",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = concat_data(train_inputs_0,train_inputs_1)\n",
    "validation_inputs = concat_data(validation_inputs_0,validation_inputs_1)\n",
    "test_inputs = concat_data(test_inputs_0,test_inputs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1773b359",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = concat_data(train_labels_0, train_labels_1)\n",
    "validation_labels = concat_data(validation_labels_0, validation_labels_1)\n",
    "test_labels = concat_data(test_labels_0, test_labels_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89f53a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = concat_data(train_mask_0, train_mask_1)\n",
    "validation_mask = concat_data(validation_mask_0, validation_mask_1)\n",
    "test_mask = concat_data(test_mask_0, test_mask_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e3db33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16856, 256)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_inputs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc4f5bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16856, 256)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a82584ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_inputs_0\n",
    "del train_inputs_1\n",
    "del test_inputs_0\n",
    "del test_inputs_1\n",
    "del validation_inputs_0\n",
    "del validation_labels_1\n",
    "del train_labels_0\n",
    "del train_labels_1\n",
    "del train_mask_0\n",
    "del train_mask_1\n",
    "del test_labels_0\n",
    "del test_labels_1\n",
    "del test_mask_0\n",
    "del test_mask_1\n",
    "del validation_mask_0\n",
    "del validation_mask_1\n",
    "del validation_inputs_1\n",
    "del validation_labels_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8e118ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input_ids = Input(shape=(256,), dtype='int64')\n",
    "    attention_mask = Input(shape=(256,), dtype='int64')\n",
    "\n",
    "    print('Loading XLNetModel')\n",
    "    xlnetModel = TFXLNetModel.from_pretrained('xlnet-base-cased')\n",
    "    conv1D_shared = Conv1D(64, kernel_size=(7), strides=(2),kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "    batchN = BatchNormalization()\n",
    "    activa = Activation('relu')\n",
    "#     attent = Attention(use_scale=True)\n",
    "    \n",
    "    xlnetout = xlnetModel.transformer({\"input_ids\": input_ids, \"attention_mask\": attention_mask})\n",
    "    x = conv1D_shared(xlnetout.last_hidden_state)\n",
    "    x = batchN(x)\n",
    "    x = activa(x)\n",
    "#     x = attent([x, x])\n",
    "    x = MaxPooling1D((3), strides=(2))(x)\n",
    "    # x = Dense(1, activation=\"relu\")(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    model = Model(inputs=[input_ids, attention_mask,], outputs=x)\n",
    "    model.summary()\n",
    "    adam = Adam(learning_rate=0.00001)\n",
    "    model.compile(optimizer=adam, loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), metrics=['acc', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "70a116a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Include the epoch in the file name (uses `str.format`)\n",
    "#     checkpoint_path = \"./tripletloss/training_model/cp-{epoch:04d}\"\n",
    "    checkpoint_path = \"./model/training_model/cp-{epoch:04d}\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "    # Create a callback that saves the model's weights every epoch\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        verbose=1,\n",
    "        save_freq=\"epoch\")\n",
    "\n",
    "#     log_dir = \"./tripletloss/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    log_dir = \"./model/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=0)\n",
    "    # %load_ext tensorboard\n",
    "    # %tensorboard --logdir logs/fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb9bcce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading XLNetModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-26 17:03:39.640249: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-26 17:03:39.644146: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-26 17:03:39.646068: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-26 17:03:39.649553: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-26 17:03:39.651485: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-26 17:03:39.653315: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-26 17:03:39.845645: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-26 17:03:39.846940: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-26 17:03:39.848183: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-26 17:03:39.849341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13807 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:01:01.0, compute capability: 7.5\n",
      "/usr/local/lib/python3.8/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n",
      "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
      "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 256)]                0         []                            \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)        [(None, 256)]                0         []                            \n",
      "                                                                                                  \n",
      " transformer (TFXLNetMainLa  TFXLNetModelOutput(last_hi   1167183   ['input_2[0][0]',             \n",
      " yer)                        dden_state=(None, 256, 768   36         'input_1[0][0]']             \n",
      "                             ),                                                                   \n",
      "                              mems=((256, None, 768),                                             \n",
      "                              (256, None, 768),                                                   \n",
      "                              (256, None, 768),                                                   \n",
      "                              (256, None, 768),                                                   \n",
      "                              (256, None, 768),                                                   \n",
      "                              (256, None, 768),                                                   \n",
      "                              (256, None, 768),                                                   \n",
      "                              (256, None, 768),                                                   \n",
      "                              (256, None, 768),                                                   \n",
      "                              (256, None, 768),                                                   \n",
      "                              (256, None, 768),                                                   \n",
      "                              (256, None, 768)),                                                  \n",
      "                              hidden_states=None, atten                                           \n",
      "                             tions=None)                                                          \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)             (None, 125, 64)              344128    ['transformer[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 125, 64)              256       ['conv1d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 125, 64)              0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1  (None, 62, 64)               0         ['activation[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 3968)                 0         ['max_pooling1d[0][0]']       \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    3969      ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)        (None, 1)                    0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 117066689 (446.57 MB)\n",
      "Trainable params: 117066561 (446.57 MB)\n",
      "Non-trainable params: 128 (512.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6ee808d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1054/1054 [==============================] - ETA: 0s - loss: 4.1610 - acc: 0.7604 - precision: 0.9574 - recall: 0.6400"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-26 17:28:59.801521: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5898240000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to ./model/training_model/cp-0001\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116deb880>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116d32700>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116d3e5b0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116d4a4f0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116d54430>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c61370>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c6b2b0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c751f0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c80130>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c8a0a0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116b5b040>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116b65f10>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./model/training_model/cp-0001/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/training_model/cp-0001/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1054/1054 [==============================] - 1457s 1s/step - loss: 4.1610 - acc: 0.7604 - precision: 0.9574 - recall: 0.6400 - val_loss: 1.2716 - val_acc: 0.9525 - val_precision: 0.9323 - val_recall: 0.9954\n",
      "Epoch 2/4\n",
      "1054/1054 [==============================] - ETA: 0s - loss: 4.1057 - acc: 0.7998 - precision: 0.9910 - recall: 0.6815"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-26 17:53:46.100245: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5898240000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: saving model to ./model/training_model/cp-0002\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116deb880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116deb880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116d32700>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116d32700>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116d3e5b0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116d3e5b0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116d4a4f0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116d4a4f0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116d54430>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116d54430>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c61370>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c61370>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c6b2b0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c6b2b0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c751f0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c751f0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c80130>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c80130>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c8a0a0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c8a0a0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116b5b040>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116b5b040>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116b65f10>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116b65f10>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/training_model/cp-0002/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/training_model/cp-0002/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1054/1054 [==============================] - 1484s 1s/step - loss: 4.1057 - acc: 0.7998 - precision: 0.9910 - recall: 0.6815 - val_loss: 1.4167 - val_acc: 0.8709 - val_precision: 0.8278 - val_recall: 0.9985\n",
      "Epoch 3/4\n",
      "1054/1054 [==============================] - ETA: 0s - loss: 4.0742 - acc: 0.7900 - precision: 0.9850 - recall: 0.6697"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-26 18:17:58.016324: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5898240000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: saving model to ./model/training_model/cp-0003\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116deb880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116deb880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116d32700>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116d32700>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116d3e5b0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116d3e5b0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116d4a4f0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116d4a4f0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116d54430>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116d54430>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c61370>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c61370>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c6b2b0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c6b2b0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c751f0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c751f0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c80130>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c80130>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c8a0a0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c8a0a0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116b5b040>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116b5b040>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116b65f10>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116b65f10>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/training_model/cp-0003/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/training_model/cp-0003/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1054/1054 [==============================] - 1453s 1s/step - loss: 4.0742 - acc: 0.7900 - precision: 0.9850 - recall: 0.6697 - val_loss: 1.1476 - val_acc: 0.9720 - val_precision: 0.9600 - val_recall: 0.9962\n",
      "Epoch 4/4\n",
      "1054/1054 [==============================] - ETA: 0s - loss: 3.9808 - acc: 0.8037 - precision: 0.9939 - recall: 0.6860"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-26 18:42:10.848395: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5898240000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: saving model to ./model/training_model/cp-0004\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116deb880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116deb880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116d32700>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116d32700>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116d3e5b0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116d3e5b0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116d4a4f0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116d4a4f0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116d54430>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116d54430>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c61370>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c61370>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c6b2b0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c6b2b0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c751f0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c751f0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c80130>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c80130>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c8a0a0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116c8a0a0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116b5b040>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116b5b040>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116b65f10>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7f8116b65f10>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/training_model/cp-0004/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/training_model/cp-0004/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1054/1054 [==============================] - 1452s 1s/step - loss: 3.9808 - acc: 0.8037 - precision: 0.9939 - recall: 0.6860 - val_loss: 1.1060 - val_acc: 0.9886 - val_precision: 0.9915 - val_recall: 0.9900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f82b02b6370>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "model.fit(x=[train_inputs,train_mask], y=train_labels,\n",
    "          validation_data=([validation_inputs,validation_mask], validation_labels),\n",
    "          batch_size=batch_size,epochs=4,verbose=1,\n",
    "          shuffle=True,\n",
    "          callbacks=[tensorboard_callback, cp_callback]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f85e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = model.predict(x=[test_inputs,np.array(test_mask)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec306f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = preds.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f610928",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './model/training_model/cp-0002'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4d241682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "xlnetModel = tf.keras.models.load_model(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac4522c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 52s 751ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = xlnetModel.predict(x=[test_inputs,np.array(test_mask)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6cb6cfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fb660870",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9632fd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC Score: 0.9957854150799695\n"
     ]
    }
   ],
   "source": [
    "auc_roc_score = roc_auc_score(test_labels,preds)\n",
    "print(\"AUC-ROC Score:\", auc_roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3320d2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
